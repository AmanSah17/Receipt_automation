{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa5339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72a4a501",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93033d33",
   "metadata": {},
   "source": [
    "### Total Number of .pdf files present in the workdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e38f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Total : 181 PDFs in the working directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Lets create a fucnction to find .pdf files and marrk them in pdf_files\n",
    "def get_all_pdfs(root_dir):\n",
    "    pdf_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for f in filenames:\n",
    "            if f.lower().endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(dirpath, f))\n",
    "    return pdf_files\n",
    "\n",
    "\n",
    "# Set the target directory\n",
    "target_dir = r\"F://automate-accounts//automate-accouts-software-//automate-accounts-developer-hiring-assessment\"\n",
    "pdfs = get_all_pdfs(target_dir)\n",
    "print(f\"Found Total : {len(pdfs)} PDFs in the working directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564473d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "744fcc58",
   "metadata": {},
   "source": [
    "## Technical Background: How pdfplumber Works\n",
    "\n",
    "## Overview\n",
    "`pdfplumber` is a Python library designed for extracting text, tables, and metadata from PDF files. It provides fine-grained access to the content and layout of each page, making it especially useful for structured data extraction and document analysis.\n",
    "\n",
    "## How pdfplumber Works\n",
    "- **PDF Parsing:** pdfplumber is built on top of the `pdfminer.six` library, which parses the raw PDF file format. PDF files are complex binary documents that store text, images, vector graphics, and layout instructions. pdfplumber leverages pdfminer to decode these elements into Python objects.\n",
    "- **Page Objects:** When you open a PDF with pdfplumber, each page is represented as a `Page` object. This object contains methods to extract text, tables, images, and geometric information.\n",
    "- **Text Extraction:** pdfplumber can extract text in two ways:\n",
    "    - **Raw Text:** Using `page.extract_text()`, it reconstructs the text by analyzing the position and order of characters and words on the page.\n",
    "    - **Character-Level Data:** With `page.chars`, you can access the position, font, and other metadata for every character.\n",
    "- **Table Extraction:** pdfplumber uses algorithms to detect lines and whitespace, segmenting the page into rows and columns. The `page.extract_tables()` method returns tables as lists of lists, which can be easily converted to pandas DataFrames.\n",
    "- **Layout Analysis:** pdfplumber provides access to the geometric layout of each page, including bounding boxes for text, lines, rectangles, and images. This allows for custom extraction and visualization.\n",
    "- **Image Extraction:** You can extract raster images embedded in the PDF using `page.images` and `page.to_image()` for rendering.\n",
    "\n",
    "## Features\n",
    "- **Precise Text Extraction:** Handles multi-column layouts, rotated text, and non-standard fonts.\n",
    "- **Table Detection:** Identifies tables using lines, whitespace, and text alignment.\n",
    "- **Visual Debugging:** The `page.to_image()` method lets you overlay extracted elements on the page image for debugging and validation.\n",
    "- **Metadata Access:** Extracts document metadata, page dimensions, and more.\n",
    "- **Integration:** Works seamlessly with pandas for data analysis and with matplotlib for visualization.\n",
    "\n",
    "## Typical Workflow\n",
    "1. **Open PDF:** `with pdfplumber.open('file.pdf') as pdf:`\n",
    "2. **Iterate Pages:** `for page in pdf.pages:`\n",
    "3. **Extract Text:** `text = page.extract_text()`\n",
    "4. **Extract Tables:** `tables = page.extract_tables()`\n",
    "5. **Visualize:** `img = page.to_image().draw_rects(page.extract_words())`\n",
    "6. **Convert to DataFrame:** `df = pd.DataFrame(table[1:], columns=table[0])`\n",
    "\n",
    "## Limitations\n",
    "- **Scanned PDFs:** pdfplumber cannot extract text from scanned images (use OCR libraries like pytesseract for those).\n",
    "- **Complex Layouts:** Highly complex or irregular layouts may require custom extraction logic.\n",
    "- **PDF Variability:** Not all PDFs are created equal; extraction quality depends on how the PDF was generated.\n",
    "\n",
    "## Summary\n",
    "pdfplumber is a powerful tool for extracting structured and unstructured data from PDF files, with deep access to layout and content. It is ideal for data science, document analysis, and automation tasks involving PDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ad0bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e65ca0b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc37ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import spacy\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ImageDraw import ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17aaf6",
   "metadata": {},
   "source": [
    "\n",
    "### Method 1: pdfplumber (text extraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49e3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_pdfplumber(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from {pdf_path}: {e}\")\n",
    "        text = \"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea799fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
